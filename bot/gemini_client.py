"""Szczypior Discord Bot - Klient Gemini AI."""

import os
from typing import Optional, List, Dict, Any
import google.generativeai as genai
from dotenv import load_dotenv

# Wczytaj zmienne Å›rodowiskowe
load_dotenv()


class GeminiClient:
    """Klient do komunikacji z Google Gemini AI."""
    
    def __init__(self, model_name: str = "gemini-2.5-flash", 
                 system_instruction: Optional[str] = None):
        """
        Inicjalizuje klienta Gemini.
        
        Args:
            model_name: Nazwa modelu Gemini do uÅ¼ycia
            system_instruction: System prompt/instrukcja dla modelu
        """
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            raise ValueError("Nie znaleziono klucza GEMINI_API_KEY w zmiennych Å›rodowiskowych.")
            
        # Konfiguracja Gemini
        genai.configure(api_key=api_key)
        
        # DomyÅ›lna instrukcja systemowa dla analizy aktywnoÅ›ci sportowych
        if system_instruction is None:
            system_instruction = """JesteÅ› asystentem AI specjalizujÄ…cym siÄ™ w analizie aktywnoÅ›ci sportowych.
Twoim zadaniem jest dokÅ‚adne wyciÄ…ganie informacji z opisÃ³w treningÃ³w i aktywnoÅ›ci fizycznych.

WAÅ»NE ZASADY:
1. Zawsze zwracaj dane w formacie JSON
2. Typ aktywnoÅ›ci musi byÄ‡ jednym z: bieganie_teren, bieganie_bieznia, plywanie, rower, spacer, cardio
3. Dystans zawsze w kilometrach (km)
4. ObciÄ…Å¼enie w kilogramach (kg)
5. PrzewyÅ¼szenie w metrach (m)
6. JeÅ›li brak informacji, zwrÃ³Ä‡ null
7. BÄ…dÅº konserwatywny - lepiej zwrÃ³ciÄ‡ null niÅ¼ zgadywaÄ‡
8. Dla zdjÄ™Ä‡ bez tekstu, analizuj widoczne dane z aplikacji sportowych"""
        
        # Inicjalizacja modelu
        self.model_name = model_name
        self.system_instruction = system_instruction
        self.model = genai.GenerativeModel(model_name)
        
        # Historia konwersacji (opcjonalne)
        self.chat_history: List[Dict[str, str]] = []


    
    def generate_text(self, prompt: str, temperature: float = 0.7, 
                     max_tokens: Optional[int] = None) -> str:
        """
        Generuje tekst na podstawie promptu.
        
        Args:
            prompt: Prompt dla modelu
            temperature: Temperatura generowania (0.0-1.0)
            max_tokens: Maksymalna liczba tokenÃ³w (opcjonalne)
            
        Returns:
            Wygenerowany tekst
        """
        try:
            generation_config = {
                "temperature": temperature,
            }
            if max_tokens:
                generation_config["max_output_tokens"] = max_tokens
            
            response = self.model.generate_content(
                prompt,
                generation_config=generation_config
            )
            
            return response.text
        except Exception as e:
            raise Exception(f"BÅ‚Ä…d generowania tekstu: {e}")
    
    def chat(self, message: str, use_history: bool = True) -> str:
        """
        Prowadzi konwersacjÄ™ z modelem z zachowaniem historii.
        
        Args:
            message: WiadomoÅ›Ä‡ uÅ¼ytkownika
            use_history: Czy uÅ¼ywaÄ‡ historii konwersacji
            
        Returns:
            OdpowiedÅº modelu
        """
        try:
            if use_history and self.chat_history:
                # UÅ¼yj chat session z historiÄ…
                chat = self.model.start_chat(history=self._format_history())
                response = chat.send_message(message)
            else:
                # Pojedyncze zapytanie bez historii
                response = self.model.generate_content(message)
            
            # Dodaj do historii
            if use_history:
                self.chat_history.append({"role": "user", "content": message})
                self.chat_history.append({"role": "assistant", "content": response.text})
            
            return response.text
        except Exception as e:
            raise Exception(f"BÅ‚Ä…d czatu: {e}")
    
    def _format_history(self) -> List[Dict[str, str]]:
        """
        Formatuje historiÄ™ konwersacji dla Gemini API.
        
        Returns:
            Lista z historiÄ… w formacie Gemini
        """
        formatted = []
        for entry in self.chat_history:
            formatted.append({
                "role": "user" if entry["role"] == "user" else "model",
                "parts": [entry["content"]]
            })
        return formatted
    
    def clear_history(self):
        """CzyÅ›ci historiÄ™ konwersacji."""
        self.chat_history = []
    
    def analyze_activity_from_image(self, image_url: str, text_context: Optional[str] = None) -> Dict[str, Any]:
        """
        Analizuje obraz aktywnoÅ›ci sportowej (screenshot z aplikacji, zdjÄ™cie).
        
        Args:
            image_url: URL obrazu do analizy
            text_context: Opcjonalny tekst towarzyszÄ…cy obrazowi
            
        Returns:
            SÅ‚ownik z informacjami o aktywnoÅ›ci
        """
        try:
            import requests
            from PIL import Image
            from io import BytesIO
            
            # Pobierz obraz
            response = requests.get(image_url)
            image_bytes = response.content
            
            # OkreÅ›l typ MIME na podstawie Content-Type
            content_type = response.headers.get('content-type', 'image/jpeg')
            
            # Przygotuj prompt
            if text_context:
                prompt_text = f"""Przeanalizuj to zdjÄ™cie aktywnoÅ›ci sportowej wraz z kontekstem tekstowym.

Tekst uÅ¼ytkownika: "{text_context}"

WyciÄ…gnij nastÄ™pujÄ…ce informacje i zwrÃ³Ä‡ TYLKO obiekt JSON (bez markdown):
{{
  "typ_aktywnosci": "jeden z [bieganie_teren, bieganie_bieznia, plywanie, rower, spacer, cardio]",
  "dystans": float,
  "czas": "string lub null",
  "tempo": "string lub null",
  "obciazenie": float lub null,
  "przewyzszenie": float lub null,
  "kalorie": int lub null,
  "puls_sredni": int lub null,
  "komentarz": "string"
}}

WAÅ»NE:
- Przeanalizuj dokÅ‚adnie dane widoczne na zdjÄ™ciu (aplikacja Garmin, Strava, itp.)
- JeÅ›li dane nie sÄ… widoczne, zwrÃ³Ä‡ null
- Dystans ZAWSZE w kilometrach
- BÄ…dÅº precyzyjny - przepisuj dokÅ‚adne wartoÅ›ci ze zdjÄ™cia
- ZwrÃ³Ä‡ TYLKO JSON, bez ```json ani innych formatowaÅ„"""
            else:
                prompt_text = """Przeanalizuj to zdjÄ™cie aktywnoÅ›ci sportowej.

WyciÄ…gnij nastÄ™pujÄ…ce informacje i zwrÃ³Ä‡ TYLKO obiekt JSON (bez markdown):
{
  "typ_aktywnosci": "jeden z [bieganie_teren, bieganie_bieznia, plywanie, rower, spacer, cardio]",
  "dystans": float,
  "czas": "string lub null",
  "tempo": "string lub null",
  "obciazenie": float lub null,
  "przewyzszenie": float lub null,
  "kalorie": int lub null,
  "puls_sredni": int lub null,
  "komentarz": "string"
}

WAÅ»NE:
- Przeanalizuj dokÅ‚adnie dane widoczne na zdjÄ™ciu (aplikacja Garmin, Strava, itp.)
- JeÅ›li dane nie sÄ… widoczne, zwrÃ³Ä‡ null
- Dystans ZAWSZE w kilometrach
- BÄ…dÅº precyzyjny - przepisuj dokÅ‚adne wartoÅ›ci ze zdjÄ™cia
- ZwrÃ³Ä‡ TYLKO JSON, bez ```json ani innych formatowaÅ„"""
            
            # UÅ¼yj generative model dla vision
            vision_model = genai.GenerativeModel("models/gemini-2.5-flash-image-preview")
            
            # Przygotuj content w poprawnej strukturze
            content = [
                {
                    "role": "user",
                    "parts": [
                        {"text": prompt_text},
                        {"mime_type": content_type, "data": image_bytes}
                    ]
                }
            ]
            
            # WyÅ›lij do Gemini z obrazem
            response = vision_model.generate_content(
                content,
                # generation_config={"temperature": 0.1}
            )
            
            # Parsuj JSON
            import json
            response_clean = response.text.strip()
            if response_clean.startswith("```json"):
                response_clean = response_clean[7:]
            if response_clean.startswith("```"):
                response_clean = response_clean[3:]
            if response_clean.endswith("```"):
                response_clean = response_clean[:-3]
            
            return json.loads(response_clean.strip())
        except Exception as e:
            raise Exception(f"BÅ‚Ä…d analizy obrazu: {e}")
    
    def generate_motivational_comment(self, current_activity: Dict[str, Any], 
                                     previous_activities: List[Dict[str, Any]]) -> str:
        """
        Generuje spersonalizowany komentarz motywacyjny na podstawie historii.
        
        Args:
            current_activity: Aktualna aktywnoÅ›Ä‡ (dict z danymi)
            previous_activities: Lista poprzednich aktywnoÅ›ci uÅ¼ytkownika
            
        Returns:
            MotywujÄ…ca wiadomoÅ›Ä‡ uwzglÄ™dniajÄ…ca kontekst
        """
        # Przygotuj kontekst z historii
        if previous_activities:
            # WeÅº ostatnie 5 aktywnoÅ›ci
            recent = previous_activities[-5:] if len(previous_activities) > 5 else previous_activities
            history_summary = []
            
            for act in recent:
                history_summary.append(
                    f"- {act.get('AktywnoÅ›Ä‡', 'N/A')}: {act.get('Dystans (km)', 0)} km, "
                    f"{act.get('Punkty', 0)} pkt (Data: {act.get('Data', 'N/A')})"
                )
            
            history_text = "\n".join(history_summary)
            total_distance = sum(float(act.get('Dystans (km)', 0)) for act in previous_activities)
            total_points = sum(int(act.get('Punkty', 0)) for act in previous_activities)
            activity_count = len(previous_activities)
        else:
            history_text = "To pierwsza zarejestrowana aktywnoÅ›Ä‡!"
            total_distance = 0
            total_points = 0
            activity_count = 0
        
        prompt = f"""Napisz krÃ³tki (2-4 zdania), motywujÄ…cy komentarz dla uÅ¼ytkownika.

AKTUALNA AKTYWNOÅšÄ†:
- Typ: {current_activity.get('typ_aktywnosci', 'nieznany')}
- Dystans: {current_activity.get('dystans', 0)} km
- Punkty: {current_activity.get('punkty', 0)}

HISTORIA UÅ»YTKOWNIKA:
- ÅÄ…cznie aktywnoÅ›ci: {activity_count}
- ÅÄ…czny dystans: {total_distance:.1f} km
- ÅÄ…czne punkty: {total_points}

Ostatnie aktywnoÅ›ci:
{history_text}

WYTYCZNE:
- BÄ…dÅº entuzjastyczny i wspierajÄ…cy
- OdnieÅ› siÄ™ do postÄ™pÃ³w (jeÅ›li widoczne)
- ZachÄ™Ä‡ do kontynuacji
- UÅ¼yj naturalnego, przyjacielskiego jÄ™zyka
- JeÅ›li to pierwsza aktywnoÅ›Ä‡, powitaj i zmotywuj
- JeÅ›li uÅ¼ytkownik poprawia wyniki, to podkreÅ›l
- Dodaj emoji dla lepszego efektu (max 2-3)"""
        
        return self.generate_text(prompt, temperature=0.8, max_tokens=200)
    
    def get_model_info(self) -> Dict[str, Any]:
        """
        Zwraca informacje o uÅ¼ywanym modelu.
        
        Returns:
            SÅ‚ownik z informacjami o modelu
        """
        return {
            "model_name": self.model_name,
            "credentials_type": "API Key",
            "chat_history_length": len(self.chat_history)
        }

    def list_available_models(self):
        """WyÅ›wietla dostÄ™pne modele Gemini."""
        print("DostÄ™pne modele Gemini:")
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                print(f"- {m.name}")


def main():
    """Funkcja testowa demonstrujÄ…ca uÅ¼ycie klienta."""
    try:
        # Inicjalizacja klienta
        print("ğŸ”„ Inicjalizacja klienta Gemini...")
        client = GeminiClient()
        print(f"âœ… Klient zainicjalizowany: {client.model_name}")

        # Test 0: Listowanie modeli
        print("\nğŸ¤– Test 0: Listowanie dostÄ™pnych modeli")
        client.list_available_models()
        
        # Test 1: Analiza obrazu (przykÅ‚adowy URL)
        print("\nğŸ“¸ Test 1: Analiza obrazu aktywnoÅ›ci")
        print("âš ï¸  Wymaga prawdziwego URL do zdjÄ™cia z aktywnoÅ›ci")
        
        # Test 2: Generowanie komentarza z kontekstem
        print("\nğŸ’¬ Test 2: Komentarz motywacyjny z historiÄ…")
        current = {
            "typ_aktywnosci": "bieganie_teren",
            "dystans": 10.5,
            "punkty": 10500
        }
        history = [
            {"AktywnoÅ›Ä‡": "bieganie_teren", "Dystans (km)": 8.0, "Punkty": 8000, "Data": "2025-11-28"},
            {"AktywnoÅ›Ä‡": "bieganie_teren", "Dystans (km)": 9.2, "Punkty": 9200, "Data": "2025-11-30"},
        ]
        comment = client.generate_motivational_comment(current, history)
        print(f"Komentarz: {comment}")
        
        # Informacje o modelu
        print("\nğŸ“‹ Informacje o modelu:")
        info = client.get_model_info()
        for key, value in info.items():
            print(f"  {key}: {value}")
        
        print("\nâœ… Testy zakoÅ„czone!")
        
    except ValueError as e:
        print(f"âŒ BÅ‚Ä…d konfiguracji: {e}")
        print("\nAby uÅ¼yÄ‡ klienta Gemini:")
        print("1. Uzyskaj klucz API z: https://aistudio.google.com/app/apikey")
        print("2. Dodaj do pliku .env: GEMINI_API_KEY=twÃ³j_klucz")
    except Exception as e:
        print(f"âŒ BÅ‚Ä…d: {e}")


if __name__ == "__main__":
    main()
