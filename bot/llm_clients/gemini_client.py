"""Szczypior Discord Bot - Klient Gemini AI."""

import json
import os
from io import BytesIO
from typing import Any, Dict, Optional

import google.generativeai as genai
import requests
from dotenv import load_dotenv
from PIL import Image

from .base_client import BaseLLMClient

# Wczytaj zmienne Å›rodowiskowe
load_dotenv()


class GeminiClient(BaseLLMClient):
    """Klient do komunikacji z Google Gemini AI."""

    def __init__(
        self,
        model_name: Optional[str] = None,
        generation_params: Optional[Dict[str, Any]] = None,
        **kwargs,
    ):
        """
        Inicjalizuje klienta Gemini.

        Args:
            model_name: Nazwa modelu Gemini do uÅ¼ycia.
            generation_params: Parametry generowania (temperature, max_tokens, itp.).
            **kwargs: Dodatkowe argumenty.
        """
        super().__init__(model_name, **kwargs)

        api_key = os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("Nie znaleziono klucza GEMINI_API_KEY w zmiennych Å›rodowiskowych.")

        genai.configure(api_key=api_key)

        # Ustaw domyÅ›lny model jeÅ›li nie podano
        if not self.model_name:
            self.model_name = "gemini-1.5-flash"

        # Zapisz parametry generowania
        self.generation_params = generation_params or {}
        
        # Model bÄ™dzie tworzony dynamicznie z system_instruction w metodach

    def _create_model(self, system_instruction: Optional[str] = None) -> genai.GenerativeModel:
        """
        Tworzy instancjÄ™ modelu z opcjonalnÄ… instrukcjÄ… systemowÄ….
        
        Args:
            system_instruction: Instrukcja systemowa dla modelu
            
        Returns:
            Instancja GenerativeModel
        """
        if system_instruction:
            return genai.GenerativeModel(
                self.model_name,
                system_instruction=system_instruction
            )
        return genai.GenerativeModel(self.model_name)

    def generate_text(
        self, 
        prompt: str, 
        temperature: Optional[float] = None, 
        max_tokens: Optional[int] = None,
        system_instruction: Optional[str] = None
    ) -> str:
        """
        Generuje tekst na podstawie promptu.

        Args:
            prompt: Prompt dla modelu.
            temperature: Temperatura generowania (0.0-1.0). JeÅ›li None, uÅ¼yje wartoÅ›ci z konfiguracji.
            max_tokens: Maksymalna liczba tokenÃ³w (opcjonalne). JeÅ›li None, uÅ¼yje wartoÅ›ci z konfiguracji.
            system_instruction: Instrukcja systemowa dla modelu (opcjonalne).

        Returns:
            Wygenerowany tekst.
        """
        try:
            # UtwÃ³rz model z system_instruction jeÅ›li podano
            model = self._create_model(system_instruction)
            
            # UÅ¼yj wartoÅ›ci z argumentÃ³w lub z konfiguracji
            generation_config = {
                "temperature": (
                    temperature
                    if temperature is not None
                    else self.generation_params.get("temperature", 0.7)
                )
            }

            tokens = (
                max_tokens
                if max_tokens is not None
                else self.generation_params.get("max_output_tokens")
            )
            if tokens:
                generation_config["max_output_tokens"] = tokens

            response = model.generate_content(prompt, generation_config=generation_config)
            return response.text
        except Exception as e:
            print(f"BÅ‚Ä…d API Gemini (generate_text): {e}")
            try:
                print(f"Prompt feedback: {response.prompt_feedback}")
            except:
                pass
            raise Exception(f"BÅ‚Ä…d generowania tekstu: {e}")

    def analyze_image(self, image_url: str, prompt: str, system_instruction: Optional[str] = None) -> Dict[str, Any]:
        """
        Analizuje obraz na podstawie dostarczonego promptu.
        UÅ¼ywa PIL do wstÄ™pnego przetworzenia obrazu.

        Args:
            image_url: URL obrazu do analizy.
            prompt: Prompt zawierajÄ…cy instrukcje dla modelu.
            system_instruction: Instrukcja systemowa dla modelu (opcjonalne).

        Returns:
            SÅ‚ownik z przeanalizowanymi danymi (wynik parsowania JSON).
        """
        try:
            # UtwÃ³rz model vision z system_instruction jeÅ›li podano
            vision_model = self._create_model(system_instruction)
            
            # Pobierz obraz
            response = requests.get(image_url, timeout=10)
            response.raise_for_status()  # SprawdÅº czy pobieranie siÄ™ udaÅ‚o

            # OtwÃ³rz obraz za pomocÄ… PIL
            image = Image.open(BytesIO(response.content))

            # Opcjonalna optymalizacja: zmniejsz rozmiar jeÅ›li obraz jest bardzo duÅ¼y
            max_size = (2048, 2048)
            if image.width > max_size[0] or image.height > max_size[1]:
                print(f"Zmniejszam obraz z {image.size} do maks. {max_size}")
                image.thumbnail(max_size, Image.Resampling.LANCZOS)

            # Konwertuj do RGB jeÅ›li potrzeba (usuwa kanaÅ‚ alpha)
            if image.mode in ("RGBA", "LA", "P"):
                print(f"KonwertujÄ™ obraz z {image.mode} do RGB")
                background = Image.new("RGB", image.size, (255, 255, 255))
                if image.mode == "P":
                    image = image.convert("RGBA")
                background.paste(
                    image, mask=image.split()[-1] if image.mode in ("RGBA", "LA") else None
                )
                image = background

            # Zapisz przetworzone zdjÄ™cie do bajtÃ³w
            buffer = BytesIO()
            image.save(buffer, format="JPEG", quality=85)
            image_bytes = buffer.getvalue()
            content_type = "image/jpeg"

            print(f"âœ… Przetworzono obraz: rozmiar={len(image_bytes)} bajtÃ³w, wymiary={image.size}")

            # Przygotuj content dla API
            content = [prompt, {"mime_type": content_type, "data": image_bytes}]

            # WyÅ›lij do Gemini
            response = vision_model.generate_content(content)

            # WyczyÅ›Ä‡ i sparsuj odpowiedÅº JSON
            response_text = response.text.strip().replace("```json", "").replace("```", "")

            try:
                parsed_result = json.loads(response_text)

                # SprawdÅº czy Gemini zwrÃ³ciÅ‚ informacjÄ™ o braku aktywnoÅ›ci
                if not parsed_result.get("typ_aktywnosci") or not parsed_result.get("dystans"):
                    print(
                        f"âš ï¸ Gemini nie wykryÅ‚ aktywnoÅ›ci: {parsed_result.get('komentarz', 'Brak danych')}"
                    )
                    return parsed_result  # ZwrÃ³Ä‡ wynik z null wartoÅ›ciami

                return parsed_result

            except json.JSONDecodeError as e:
                print(f"âŒ BÅ‚Ä…d parsowania JSON z odpowiedzi Gemini: {e}")
                print(f"Surowa odpowiedÅº: {response_text[:500]}")
                # ZwrÃ³Ä‡ strukturÄ™ wskazujÄ…cÄ… na brak danych zamiast rzucania wyjÄ…tku
                return {
                    "typ_aktywnosci": None,
                    "dystans": None,
                    "komentarz": "BÅ‚Ä…d analizy obrazu - nie udaÅ‚o siÄ™ przetworzyÄ‡ odpowiedzi",
                }

        except requests.exceptions.RequestException as e:
            print(f"âŒ BÅ‚Ä…d pobierania obrazu z URL: {e}")
            return {"typ_aktywnosci": None, "dystans": None, "komentarz": "BÅ‚Ä…d pobierania obrazu"}
        except Exception as e:
            print(f"âŒ BÅ‚Ä…d API Gemini (analyze_image): {e}")
            try:
                print(f"Prompt feedback: {response.prompt_feedback}")
            except:
                pass
            return {"typ_aktywnosci": None, "dystans": None, "komentarz": "BÅ‚Ä…d analizy obrazu"}

    def get_model_info(self) -> Dict[str, Any]:
        """Zwraca informacje o uÅ¼ywanym modelu."""
        return {
            "model_name": self.model_name,
            "credentials_type": "API Key",
            "supports_system_instruction": True,
        }

    def list_available_models(self):
        """WyÅ›wietla dostÄ™pne modele Gemini, ktÃ³re wspierajÄ… generowanie treÅ›ci."""
        print("DostÄ™pne modele Gemini (do generowania treÅ›ci):")
        for m in genai.list_models():
            if "generateContent" in m.supported_generation_methods:
                print(f"- {m.name}")


def main():
    """Funkcja testowa demonstrujÄ…ca uÅ¼ycie uproszczonego klienta."""
    try:
        print("ğŸ”„ Inicjalizacja klienta Gemini...")
        client = GeminiClient()
        print(f"âœ… Klient zainicjalizowany. Model: {client.model_name}")

        # Test 1: Listowanie modeli
        print("\nğŸ¤– Test 1: Listowanie dostÄ™pnych modeli")
        client.list_available_models()

        # Test 2: Generowanie tekstu
        print("\nğŸ“ Test 2: Generowanie prostego tekstu")
        prompt_text = "Napisz krÃ³tki, motywujÄ…cy cytat o sporcie."
        generated_text = client.generate_text(prompt_text)
        print(f"Prompt: '{prompt_text}'")
        print(f"OdpowiedÅº: {generated_text}")

        # Test 3: Analiza obrazu (wymaga URL)
        print("\nğŸ“¸ Test 3: Analiza obrazu (przykÅ‚adowy prompt)")
        print("âš ï¸  Wymaga prawdziwego URL do zdjÄ™cia z aktywnoÅ›ciÄ… sportowÄ….")
        image_url = "https://i.imgur.com/c4b8jZg.png"  # PrzykÅ‚adowy URL, moÅ¼e nie dziaÅ‚aÄ‡

        analysis_prompt = """Przeanalizuj to zdjÄ™cie aktywnoÅ›ci sportowej.
WyciÄ…gnij nastÄ™pujÄ…ce informacje i zwrÃ³Ä‡ TYLKO obiekt JSON:
{
  "typ_aktywnosci": "jeden z [bieganie_teren, bieganie_bieznia, rower]",
  "dystans": float
}"""
        try:
            analysis_result = client.analyze_image(image_url, analysis_prompt)
            print("Wynik analizy obrazu:")
            print(json.dumps(analysis_result, indent=2))
        except Exception as e:
            print(
                f"Nie udaÅ‚o siÄ™ przeanalizowaÄ‡ obrazu (to normalne, jeÅ›li URL jest nieaktywny): {e}"
            )

        print("\nâœ… Testy zakoÅ„czone!")

    except ValueError as e:
        print(f"âŒ BÅ‚Ä…d konfiguracji: {e}")
    except Exception as e:
        print(f"âŒ WystÄ…piÅ‚ nieoczekiwany bÅ‚Ä…d: {e}")


if __name__ == "__main__":
    main()
