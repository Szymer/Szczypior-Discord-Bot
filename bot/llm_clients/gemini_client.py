"""Szczypior Discord Bot - Klient Gemini AI."""

import os
from typing import Optional, Dict, Any
import google.generativeai as genai
from dotenv import load_dotenv
import requests
import json
from .base_client import BaseLLMClient

# Wczytaj zmienne Å›rodowiskowe
load_dotenv()


class GeminiClient(BaseLLMClient):
    """Klient do komunikacji z Google Gemini AI."""
    
    def __init__(self, model_name: Optional[str] = None, generation_params: Optional[Dict[str, Any]] = None, **kwargs):
        """
        Inicjalizuje klienta Gemini.
        
        Args:
            model_name: Nazwa modelu Gemini do uÅ¼ycia.
            generation_params: Parametry generowania (temperature, max_tokens, itp.).
            **kwargs: Dodatkowe argumenty.
        """
        super().__init__(model_name, **kwargs)
        
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            raise ValueError("Nie znaleziono klucza GEMINI_API_KEY w zmiennych Å›rodowiskowych.")
            
        genai.configure(api_key=api_key)
        
        # Ustaw domyÅ›lny model jeÅ›li nie podano
        if not self.model_name:
            self.model_name = "gemini-1.5-flash"
        
        self.model = genai.GenerativeModel(self.model_name)
        self.vision_model = genai.GenerativeModel(self.model_name)
        
        # Zapisz parametry generowania
        self.generation_params = generation_params or {}

    def generate_text(self, prompt: str, temperature: Optional[float] = None, 
                     max_tokens: Optional[int] = None) -> str:
        """
        Generuje tekst na podstawie promptu.
        
        Args:
            prompt: Prompt dla modelu.
            temperature: Temperatura generowania (0.0-1.0). JeÅ›li None, uÅ¼yje wartoÅ›ci z konfiguracji.
            max_tokens: Maksymalna liczba tokenÃ³w (opcjonalne). JeÅ›li None, uÅ¼yje wartoÅ›ci z konfiguracji.
            
        Returns:
            Wygenerowany tekst.
        """
        try:
            # UÅ¼yj wartoÅ›ci z argumentÃ³w lub z konfiguracji
            generation_config = {
                "temperature": temperature if temperature is not None else self.generation_params.get("temperature", 0.7)
            }
            
            tokens = max_tokens if max_tokens is not None else self.generation_params.get("max_output_tokens")
            if tokens:
                generation_config["max_output_tokens"] = tokens
            
            response = self.model.generate_content(prompt, generation_config=generation_config)
            return response.text
        except Exception as e:
            print(f"BÅ‚Ä…d API Gemini (generate_text): {e}")
            try:
                print(f"Prompt feedback: {response.prompt_feedback}")
            except:
                pass
            raise Exception(f"BÅ‚Ä…d generowania tekstu: {e}")

    def analyze_image(self, image_url: str, prompt: str) -> Dict[str, Any]:
        """
        Analizuje obraz na podstawie dostarczonego promptu.
        
        Args:
            image_url: URL obrazu do analizy.
            prompt: Prompt zawierajÄ…cy instrukcje dla modelu.
            
        Returns:
            SÅ‚ownik z przeanalizowanymi danymi (wynik parsowania JSON).
        """
        try:
            # Pobierz obraz
            response = requests.get(image_url)
            response.raise_for_status()  # SprawdÅº czy pobieranie siÄ™ udaÅ‚o
            image_bytes = response.content
            content_type = response.headers.get('content-type', 'image/jpeg')
            
            # Przygotuj content dla API
            content = [
                prompt,
                {"mime_type": content_type, "data": image_bytes}
            ]
            
            # WyÅ›lij do Gemini
            response = self.vision_model.generate_content(content)
            
            # WyczyÅ›Ä‡ i sparsuj odpowiedÅº JSON
            response_text = response.text.strip().replace("```json", "").replace("```", "")
            return json.loads(response_text)
            
        except requests.exceptions.RequestException as e:
            raise Exception(f"BÅ‚Ä…d pobierania obrazu z URL: {e}")
        except json.JSONDecodeError as e:
            raise Exception(f"BÅ‚Ä…d parsowania JSON z odpowiedzi Gemini: {e}\nOdpowiedÅº: {response.text}")
        except Exception as e:
            print(f"BÅ‚Ä…d API Gemini (analyze_image): {e}")
            try:
                print(f"Prompt feedback: {response.prompt_feedback}")
            except:
                pass
            raise Exception(f"BÅ‚Ä…d analizy obrazu: {e}")

    def get_model_info(self) -> Dict[str, Any]:
        """Zwraca informacje o uÅ¼ywanym modelu."""
        return {
            "model_name": self.model_name,
            "vision_model_name": self.vision_model.model_name,
            "credentials_type": "API Key",
        }

    def list_available_models(self):
        """WyÅ›wietla dostÄ™pne modele Gemini, ktÃ³re wspierajÄ… generowanie treÅ›ci."""
        print("DostÄ™pne modele Gemini (do generowania treÅ›ci):")
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                print(f"- {m.name}")


def main():
    """Funkcja testowa demonstrujÄ…ca uÅ¼ycie uproszczonego klienta."""
    try:
        print("ğŸ”„ Inicjalizacja klienta Gemini...")
        client = GeminiClient()
        print(f"âœ… Klient zainicjalizowany. Model: {client.model_name}")

        # Test 1: Listowanie modeli
        print("\nğŸ¤– Test 1: Listowanie dostÄ™pnych modeli")
        client.list_available_models()
        
        # Test 2: Generowanie tekstu
        print("\nğŸ“ Test 2: Generowanie prostego tekstu")
        prompt_text = "Napisz krÃ³tki, motywujÄ…cy cytat o sporcie."
        generated_text = client.generate_text(prompt_text)
        print(f"Prompt: '{prompt_text}'")
        print(f"OdpowiedÅº: {generated_text}")

        # Test 3: Analiza obrazu (wymaga URL)
        print("\nğŸ“¸ Test 3: Analiza obrazu (przykÅ‚adowy prompt)")
        print("âš ï¸  Wymaga prawdziwego URL do zdjÄ™cia z aktywnoÅ›ciÄ… sportowÄ….")
        image_url = "https://i.imgur.com/c4b8jZg.png" # PrzykÅ‚adowy URL, moÅ¼e nie dziaÅ‚aÄ‡
        
        analysis_prompt = """Przeanalizuj to zdjÄ™cie aktywnoÅ›ci sportowej.
WyciÄ…gnij nastÄ™pujÄ…ce informacje i zwrÃ³Ä‡ TYLKO obiekt JSON:
{
  "typ_aktywnosci": "jeden z [bieganie_teren, bieganie_bieznia, rower]",
  "dystans": float
}"""
        try:
            analysis_result = client.analyze_image(image_url, analysis_prompt)
            print("Wynik analizy obrazu:")
            print(json.dumps(analysis_result, indent=2))
        except Exception as e:
            print(f"Nie udaÅ‚o siÄ™ przeanalizowaÄ‡ obrazu (to normalne, jeÅ›li URL jest nieaktywny): {e}")

        print("\nâœ… Testy zakoÅ„czone!")
        
    except ValueError as e:
        print(f"âŒ BÅ‚Ä…d konfiguracji: {e}")
    except Exception as e:
        print(f"âŒ WystÄ…piÅ‚ nieoczekiwany bÅ‚Ä…d: {e}")


if __name__ == "__main__":
    main()
